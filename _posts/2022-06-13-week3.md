---
layout: post
title: Week 3
---

**Reflections from the Cascad.ai conference**

This week, a big highlight was participating in the Cascade AI conference which was very engaging and also relevant for this summer project. With the goal of building and employing AI responsibly, this conference had speakers sharing insights from both industry and academia. The conference frames the activities for the participants as these tennents:

TO ENGAGE OPENLY
Participants will engage with community members in a respectful and open-minded fashion to understand social and ethical concerns associated with AI technology development and deployment.

TO LEARN BY DOING
Those at the summit have an opportunity to understand and evaluate the potential ethical challenges associated with AI technology adoption within their organizations.

TO SHARE INSIGHTS
Attendees will provide insight into development and adopt processes so that best practices and lessons learned can be shared across industries.

More details about this conference can be found at their website [here](https://cascad.ai/).

**My Takeaways**

* The human-centric design of the keynote speaker really resonated, that we must be user end focused. The presenter had many interesting examples of when AI is given too much decision making power without enough ‘human oversight”. The top example of successful programming being an automatic camera. The camera software will perform many skills automatically such as focusing and light correction, but a human user points the camera and captures the image as they see it.

* It is crucial to give 'non-technical people' a seat at the table for the human rights conversations related to AI. One form of this might be in technological review boards (similar to transportation or medical review boards). Knowing this impacts our research for a data visualization tool by informing us that we might want to include data on existing review or accountability organizations for a given instance of AI.



* It is so easy for people outside of the tech world to overestimate the black box AI. Vernacular barriers make it harder for non tech people to be engaged in the process, and societally we need to take care not to fall into the trap of assuming validity due to a machine being behind a decision or process.

* The mission stated risk : “Technological innovation brings the risk of an increased socio-economic divide and a marginalization of populations and communities” 

* The mission stated reality : “If carefully considered and implemented, large-scale adoption of artificial intelligence (AI) has the potential to make a significant impact on maximizing the reward and minimizing organizational risk.” 

* The way forward with ethical AI : “With the rise of smart technology, AI is now touching more parts of our lives and the world of business and industry than ever before. This introduces a need to place trust in algorithms that constantly evolve as machines learn how to do specific tasks more effectively or to address new challenges. Organizations who take steps to safeguard their consumers will demonstrate desired social responsibility and also secure a competitive advantage.” 
