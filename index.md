---
layout: default
title: DREAM Project Site
---

## About Me

I am currently completing my Master's in Computer Science at Northeastern University in Boston, MA. I received my undergraduate degree in Geosciences from Wellesley University in 2019 and proceeded to thru hike the Appalachian Trail. I then managed a C.P.A. firm for two years before returning to school to begin my masters. I’m looking forward to continuing to synthesize my love of environmental justice with computing capabilities as I finish my masters in the spring of 2023 and beyond.

## About My Advisor

John Alexis Guerra Gómez is an Information Visualization Researcher and Engineer. In his own words: "I help people extract insights from their data using interactive infovis and data science. PhD in Computer Science, Assistant Teaching Professor at Northeastern University Bay Area. I conduct research on Visual Analytics, Accessibility, Big data, Human Computer Interaction and Web Development. Formerly at UCBerkeley, Uniandes Colombia, Yahoo Labs, Xerox PARC and DUTO."

You can access his website at [this link](https://johnguerra.co/)

## About Our Project

#Abstract to our Research Paper#

*This paper reviews literature on best practices in data visualization of irresponsible Artificial Intelligence (AI) instances. The introduction speaks about data visualization’s ability to communicate data as well as to aid in development of new data and insights. We explain our motivation in how the irresponsible Artificial Intelligence dataset can help domain experts support more accountability in AI. We explore identified risks in data visualization, and present our countermeasure through catering our tool to the nuances of our data and user stories. We outline our data and ideal user, review best practices, then outline proposed features that would enable our data visualization to be a successful tool.*

The general area for our research project is data visualization for instances of irresponsible artificial intelligence. This means that we research and improve the best practices for visualizing this kind of data, with domain experts being our main audience. We are working in observable notebook with d3 and Vega-Lite. The following interactive tool was built by John, our research advisor, to explore datasets. This tool is an example of what we would aim to build, or at least propose features for, during this project. This instance of the navio is loaded with data from our project, so you can also explore our dataset below.

<iframe width="100%" height="350" frameborder="0" src="https://observablehq.com/embed/@nolenbelle/learning-with-the-ai-data?cells=viewof+rawData"></iframe>

The specific problem we are working on tackling is that AI in its current state is often unfair, furthers pre-existing societal discrimination, and is difficult to control. Our solution is to build an Irresponsible AI Atlas to track what instances of irresponsible AI actually exist, in order to foster more discussion and action toward accountability.

There is a knowledge gap we aim to cover with the AI Atlas, as well as a knowledge gap that we aim to cover in our research. The gap we aim to cover with the AI Atlas is: What instances of Irresponsible AI exist? We want to track all records of them in one place. The gap our research aims to cover is: Can an Interactive Visualization Tool better support the analysis of data from instances of irresponsible AI? 

We can explore this question through research on what features have made for successful data visualization tools in this domain, in the past. We will conduct a literature review on best practices. One key to answering this question will be developing specific usage scenarios for the specific audience that might use our tool. 

Here is an example of the backlogs of usage scenarios:
* Rachel, a phd student who does research to support AI accountability organizations, wants to be able to view the descriptions of an incident and company responsible, associated with a scatterplot point by clicking on it

* Rachel wants to look at the instances of irresponsible AI on a timeline, in order to determine if the impact on specific marginalized populations are growing with time

* Rachel wants to be able to select a small section in the timeline, and zoom in to look at instances of irresponsible AI just in that timeframe, for example, looking at specific dates associated with presidential terms

* Rachel is an AI researcher who wants to compare the domestic versus international impact of US companies irresponsibly using AI (we are trying to come up with any useful use cases that are map specific, or at least using location data.

[My Final Report](files/finalreport.pdf)

## My Blog

[My Blog](blog.html)
